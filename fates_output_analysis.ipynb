{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCI Testbed for FATES\n",
    "\n",
    "The purpose of this testbed code is to compare FATES output to observations at BCI, and also to understand some of the internal paramteric control over FATES predictions.  The overall order of things is to first load an ensemble of FATES model inputs, then look at several metrics of model predictions as projected onto the trait covariance matrices that were used to generate the model ensemble, and well as looking at several model predictions as compared to observed ecosystem states and fluxes at the BCI site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we will load all the libraries that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import dateutil.parser\n",
    "import datetime\n",
    "import map_funcs\n",
    "from IPython.display import Image\n",
    "from scipy import interpolate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# set the plot style\n",
    "plt.style.use('seaborn-ticks')\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5, \"lines.markersize\": 6.0, 'lines.markeredgewidth': 1.0})\n",
    "#sns.set_context(\"poster\")\n",
    "\n",
    "print(sns.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First steps: load the data and plot some basic properties\n",
    "\n",
    "\n",
    "Load all the FATES history output that was generated by the model ensemble, as well as the traits matrix input to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### uncomment this for bare-ground runs\n",
    "filename_history = '/Users/cdkoven/datasets/fates_output/bci_testbed/fates_clm5_fullmodel_bci_parameter_ensemble_1pft_190329_multiinst_576inst_b9c92b7_106ac7a.h0.ensemble.sofar.nc'\n",
    "\n",
    "## now load the size-structured data.  it is on a second history tape with an annual write frequency\n",
    "filename_history2 = '/Users/cdkoven/datasets/fates_output/bci_testbed/fates_clm5_fullmodel_bci_parameter_ensemble_1pft_190329_multiinst_576inst_b9c92b7_106ac7a.h1.ensemble.sofar.nc'\n",
    "\n",
    "# ### uncomment this for inventory runs\n",
    "# filename_history = '/Users/cdkoven/datasets/fates_output/bci_testbed/fates_clm5_fullmodel_bci_parameter_ensemble_1pft_v004inv_b1bf522_819609f.h0.ensemble.sofar.nc'\n",
    "\n",
    "filename_params = '/Users/cdkoven/datasets/fates_output/bci_testbed/fates_params_default_106ac7a_mod1PFT_exp1.ensemble.c190329.nc'\n",
    "\n",
    "histfile = nc4.Dataset(filename_history)\n",
    "paramfile = nc4.Dataset(filename_params)\n",
    "histfile2 = nc4.Dataset(filename_history2)\n",
    "\n",
    "traits_matrix = np.loadtxt('traits_matrix_used_in_param_files_190329.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next lets look at which ensemble members predict a surviving forest.  Calculate an index of survival and project that back on to the trait covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biomass_var = histfile.variables['AGB']\n",
    "\n",
    "nens = biomass_var.shape[0]\n",
    "nts = biomass_var.shape[1]\n",
    "nyears = nts/12\n",
    "print(nens)\n",
    "\n",
    "startyear = nyears-50\n",
    "endyear = nyears-1\n",
    "\n",
    "\n",
    "survival_threshold = 100.\n",
    "survived = biomass_var[:,nts-1,0] > survival_threshold\n",
    "print(' fraction of ensemble members with surviving forests = '+str(survived.sum()/float(nens)))\n",
    "\n",
    "\n",
    "#column_names = ['Vcmax25', 'wood_dens', 'LMA', 'N/area','leaf_life','b_mort','crown_dbh_coef','crown_dbh_exp','bleaf_dbh','fineroot_leaf','npp_repro','cstarv_mort']\n",
    "column_names = ['Vcmax25top', 'Wood Dens.', 'LMA', 'Leaf N/area','Leaf Lifespan','Back. Mort.','Cr. Area Coef','Cr. Area Exp','Bleaf Allom.','Fine Root:Leaf','NPP Repr.','C Starv Mort.']\n",
    "\n",
    "ncols = len(column_names)\n",
    "print(ncols)\n",
    "print(traits_matrix.shape)\n",
    "print(len(survived))\n",
    "\n",
    "df_traits = pd.DataFrame(traits_matrix, columns=column_names)\n",
    "\n",
    "columns_log = [0,2,3,4,5,11]\n",
    "column_names_log = ['log Vcmax25', 'wood_dens', 'log LMA', 'log N/area','log leaf_life','log b_mort','crown_dbh_coef','crown_dbh_exp','bleaf_dbh','fineroot_leaf','npp_repro','log cstarv_mort']\n",
    "traits_matrix_partiallylog = traits_matrix.copy()\n",
    "for i in range(len(columns_log)):\n",
    "    traits_matrix_partiallylog[:,columns_log[i]] = np.ma.log10(traits_matrix_partiallylog[:,columns_log[i]])\n",
    "df_traits_log = pd.DataFrame(traits_matrix_partiallylog, columns=column_names_log)\n",
    "\n",
    "#colors = 1. + 10. * survived\n",
    "#pd.plotting.scatter_matrix(df_traits, alpha=0.7, figsize=(30,30), diagonal='hist', c=colors, s=80)\n",
    "\n",
    "df_traits_log[\"survival\"] = pd.cut(survived, bins=[-1,0.5,2.], labels=['Dead','Alive'])\n",
    "\n",
    "survivalplot = sns.pairplot(df_traits_log, hue=\"survival\",\n",
    "                 hue_order=df_traits_log.survival.cat.categories,\n",
    "                 palette=\"YlGnBu\", diag_kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next lets plot a histogram of mean LAI values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_lai = histfile.variables['ELAI'][:,startyear*12:endyear*12,0].mean(axis=1)\n",
    "lai_series = pd.Series(mean_lai, name='LAI')\n",
    "sns.distplot(lai_series, kde=False, rug=False, color=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a joint ditribution of LAI and GPP values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_gpp = np.ma.masked_array(histfile.variables['GPP'][:,startyear*12:endyear*12,0].mean(axis=1) * 86400 *365, mask=np.logical_not(survived))\n",
    "gpp_series = pd.Series(mean_gpp, name='GPP')\n",
    "sns.jointplot(x=lai_series, y=gpp_series, color=\"k\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's now make a plot of biomass trajectories, to see where we are at in terms of steady-state and the overall progression of biomass accumulation across the ensemble members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"poster\")\n",
    "biomass_trajectory_annual = biomass_var[:,::12,0]\n",
    "biomass_trajectory_annual.shape\n",
    "time = np.arange(biomass_trajectory_annual.shape[1])\n",
    "biomass_df = pd.DataFrame(biomass_trajectory_annual)\n",
    " \n",
    "fig=plt.figure(figsize=(15, 7.5))\n",
    "\n",
    "# multiple line plot\n",
    "for column in range(nens):\n",
    "    plt.plot(time, biomass_trajectory_annual[column,:]*1e-3, marker='', linewidth=0.25, alpha=0.9, color='green')\n",
    " \n",
    "# Add titles\n",
    "#plt.title(\"Timeseries of biomass\", loc='left')\n",
    "plt.xlabel(\"Time (years since start of run)\")\n",
    "plt.ylabel(\"Aboveground Biomass (kg C / m$^2$)\")\n",
    "\n",
    "biomass_observed = 13.6  ## table S2 of Meakem et al., 2018.\n",
    "plt.plot(np.array([0.,200]), np.array([biomass_observed,biomass_observed]), color='black')\n",
    "\n",
    "plt.savefig('biomass_timeseries.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Understanding some parametric control\n",
    "\n",
    "Now we will plot several instances of the trait covariance matrix as colored by various model predictions, in order to understand how the paramters govern various model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the trait covariance matrix as colored by the final LAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traits_log[\"mean_LAI\"] = pd.cut(mean_lai, bins=np.arange(10))\n",
    "\n",
    "laiplot = sns.pairplot(df_traits_log, hue=\"mean_LAI\",\n",
    "                 hue_order=df_traits_log.mean_LAI.cat.categories,\n",
    "                 palette=\"YlGnBu\")\n",
    "\n",
    "laiplot.savefig('lai_pairplot.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, plot the trait covariance matrix as colored by final mean GPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traits_log[\"mean_gpp\"] = pd.cut(mean_gpp, bins=np.arange(10)*400.)\n",
    "\n",
    "\n",
    "gppscatterplot = sns.pairplot(df_traits_log, hue=\"mean_gpp\",\n",
    "                 hue_order=df_traits_log.mean_gpp.cat.categories,\n",
    "                 palette=\"YlGnBu\")\n",
    "\n",
    "gppscatterplot.savefig('gpp_pairplot.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, let's  plot the carbon use efficieny of the runs, as projected onto the trait covariance matrix.  Here I am defining CUE as the ratio of NPP/GPP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_npp = histfile.variables['NPP'][:,startyear*12:endyear*12,0].mean(axis=1) * 86400 *365\n",
    "\n",
    "mean_cue = np.ma.masked_array(mean_npp[:] / mean_gpp[:], mask=np.logical_not(survived))\n",
    "\n",
    "df_traits_log[\"mean_cue\"] = pd.cut(mean_cue, bins=np.arange(11)*.1)\n",
    "\n",
    "\n",
    "cuescatterplot = sns.pairplot(df_traits_log, hue=\"mean_cue\",\n",
    "                 hue_order=df_traits_log.mean_cue.cat.categories,\n",
    "                 palette=\"YlGnBu\", dropna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot autotrophic respiration itself, projected onto TCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ar = histfile.variables['AR'][:,startyear*12:endyear*12,0].mean(axis=1) * 86400 *365\n",
    "\n",
    "df_traits_log[\"mean_ar\"] = pd.cut(mean_ar, bins=np.arange(10)*200.)\n",
    "\n",
    "\n",
    "cuescatterplot = sns.pairplot(df_traits_log, hue=\"mean_ar\",\n",
    "                 hue_order=df_traits_log.mean_ar.cat.categories,\n",
    "                 palette=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The same thing , now for latent heat fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_transp = np.ma.masked_array(histfile.variables['FCTR'][:,startyear*12:endyear*12,0].mean(axis=1))\n",
    "mean_grndevap = np.ma.masked_array(histfile.variables['FGEV'][:,startyear*12:endyear*12,0].mean(axis=1))\n",
    "mean_canevap = np.ma.masked_array(histfile.variables['FCEV'][:,startyear*12:endyear*12,0].mean(axis=1))\n",
    "\n",
    "mean_lh = mean_transp + mean_grndevap + mean_canevap\n",
    "print(mean_lh.max())\n",
    "df_traits_log[\"mean_lh\"] = pd.cut(mean_lh, bins=np.arange(10)*10.)\n",
    "transpscatterplot = sns.pairplot(df_traits_log, hue=\"mean_lh\",\n",
    "                 hue_order=df_traits_log.mean_lh.cat.categories,\n",
    "                 palette=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we will look at the final biomass as projected onto the TCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_biomass = biomass_trajectory_annual[:,startyear:endyear].mean(axis=1) * 1e-3\n",
    "print(final_biomass.max())\n",
    "df_traits_log[\"final_biomass\"] = pd.cut(final_biomass, bins=np.arange(10)*5.)\n",
    "biomassscatterplot = sns.pairplot(df_traits_log, hue=\"final_biomass\",\n",
    "                 hue_order=df_traits_log.final_biomass.cat.categories,\n",
    "                 palette=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crown area index, which is the total area of plant canopies per area ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crown_area_index = histfile2.variables['CANOPY_AREA_BY_AGE'][:,startyear:endyear,:,0].mean(axis=1).sum(axis=1)\n",
    "\n",
    "df_traits_log[\"final_crown_area_index\"] = pd.cut(crown_area_index, bins=np.arange(11)*.3)\n",
    "final_crown_area_index_scatterplot = sns.pairplot(df_traits_log, hue=\"final_crown_area_index\",\n",
    "                 hue_order=df_traits_log.final_crown_area_index.cat.categories,\n",
    "                 palette=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of FATES against observational datasets\n",
    "## Eddy-Covariance Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's compare the seasonal cycles of GPP, LH, and SH against flux tower observations. First load and process the eddy covariance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bci_fluxtower_datafilename = 'benchmark_datasets/BCI_v3.1.csv'\n",
    "\n",
    "bci_fluxtower_data = np.genfromtxt(bci_fluxtower_datafilename, dtype={'names': ('date','tair','RH','vpd','p_kpa','PPT','Rs','Rs_dn','Rl_dn','Rl_up','Rnet','LE','H','Par_tot','Par_diff','SWC','ubar','ustar','WD','gpp','FLAG'),'formats': ('S16','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4','f4')}, delimiter=',', skip_header=2)\n",
    "\n",
    "ntim = len(bci_fluxtower_data)\n",
    "\n",
    "time_start = datetime.datetime(2010, 1, 1, 0, 00)\n",
    "\n",
    "tdelt = np.ma.masked_all(ntim)\n",
    "month = np.ma.masked_all(ntim, dtype=np.int)\n",
    "year = np.ma.masked_all(ntim, dtype=np.int)\n",
    "gpp = np.ma.masked_all(ntim)\n",
    "LE = np.ma.masked_all(ntim)\n",
    "H = np.ma.masked_all(ntim)\n",
    "\n",
    "for i in range(ntim):\n",
    "    ts = dateutil.parser.parse(bci_fluxtower_data[i][0])\n",
    "    tdelt[i] = (ts - time_start).days + (ts - time_start).seconds / 86400.\n",
    "    month[i] = ts.month\n",
    "    year[i] = ts.year\n",
    "    gpp[i] = bci_fluxtower_data[i][19]\n",
    "    LE[i] = bci_fluxtower_data[i][11]\n",
    "    H[i] = bci_fluxtower_data[i][12]\n",
    "\n",
    "H_masked = np.ma.masked_invalid(H)\n",
    "\n",
    "nyears = (year.max() - year.min()) + 1\n",
    "nmonths = nyears * 12\n",
    "\n",
    "gpp_monthly = np.ma.masked_all(nmonths)\n",
    "gpp_monthyear = np.ma.masked_all([nyears,12])\n",
    "LE_monthyear = np.ma.masked_all([nyears,12])\n",
    "H_monthyear = np.ma.masked_all([nyears,12])\n",
    "\n",
    "for i in range(nyears):\n",
    "    for j in range(12):\n",
    "        mask = (year[:] == (year.min() + i)) * (month[:] == (j + 1))\n",
    "        index = i*12 + j\n",
    "        # gpp_monthly2[index] = gpp[mask].mean()                                                                                                                                                                                                                              \n",
    "        if mask.sum() > 0:\n",
    "            gpp_monthly[index] = (gpp * mask).sum() / mask.sum()\n",
    "            gpp_monthyear[i,j] = gpp_monthly[index]\n",
    "            LE_monthyear[i,j] = (LE * mask).sum() / mask.sum()\n",
    "        H_monthyear[i,j] = H_masked[mask].mean()\n",
    "\n",
    "months = np.arange(12)\n",
    "\n",
    "### change gpp units to grams or carbon per meter squared per year\n",
    "gpp_gcm2y = gpp_monthyear * 1e-6 * 12.0107 * (86400 * 365.25)\n",
    "\n",
    "## write monthly gpp as a text file\n",
    "np.savetxt('benchmark_datasets/gpp_gcm2y',gpp_gcm2y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets plot seasonal cycles of GPP from FATES and the tower data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sesonal cycle of GPP from FATES ensembles\n",
    "gpp_seascycle = np.ma.masked_all([nens, 12])\n",
    "offset = 7  # first month is actually June, so I need to add this to get to January\n",
    "\n",
    "for i in range(12):\n",
    "    gpp_seascycle[:,i] = histfile.variables['GPP'][:,offset+i+(startyear)*12:offset+i+endyear*12:12,0].mean(axis=1) * 86400 *365\n",
    "\n",
    "fig=plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(months, gpp_seascycle.transpose(), linewidth=0.15, alpha=0.9, color='green')\n",
    "\n",
    "plt.plot(months, gpp_gcm2y.transpose(), marker='', linewidth=1.0, alpha=0.9, color='blue')\n",
    "\n",
    "\n",
    "plt.title(\"Seasonal cycle of GPP\", loc='left')\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"GPP (g C / m$^2$ / y)\")\n",
    "\n",
    "plt.text(7, 5200, 'Observations', color ='blue', fontsize=15)\n",
    "plt.text(7, 4900, 'FATES ensemble members', color ='green', fontsize=15)\n",
    "\n",
    "plt.savefig('gpp_seascycle.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets plot sesaonal cycles of LH from FATES and the tower data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sesonal cycle of LH from FATES ensembles\n",
    "LH_seascycle = np.ma.masked_all([nens, 12])\n",
    "\n",
    "for i in range(12):\n",
    "    LH_seascycle[:,i] = histfile.variables['FCTR'][:,offset+i+(startyear)*12:offset+i+endyear*12:12,0].mean(axis=1)\n",
    "    +histfile.variables['FGEV'][:,offset+i+(startyear)*12:offset+i+endyear*12:12,0].mean(axis=1)\n",
    "    +histfile.variables['FCEV'][:,offset+i+(startyear)*12:offset+i+endyear*12:12,0].mean(axis=1)\n",
    "    \n",
    "fig=plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(months, LH_seascycle.transpose(), linewidth=0.15, alpha=0.9, color='green')\n",
    "\n",
    "plt.plot(months, LE_monthyear.transpose(), marker='', linewidth=1.0, alpha=0.9, color='blue')\n",
    "\n",
    "\n",
    "plt.title(\"Seasonal cycle of LH\", loc='left')\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"LH (W/m$^2$)\")\n",
    "\n",
    "\n",
    "plt.text(7, 90, 'Observations', color ='blue', fontsize=15)\n",
    "plt.text(7, 83, 'FATES ensemble members', color ='green', fontsize=15)\n",
    "plt.savefig('lh_seascycle.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets plot seasonal cycles of SH from FATES and the tower data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sesonal cycle of SH from FATES ensembles\n",
    "SH_seascycle = np.ma.masked_all([nens, 12])\n",
    "\n",
    "for i in range(12):\n",
    "    SH_seascycle[:,i] = histfile.variables['FSH'][:,offset+i+(startyear)*12:offset+i+endyear*12:12,0].mean(axis=1)\n",
    "\n",
    "fig=plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(months, SH_seascycle.transpose(), linewidth=0.15, alpha=0.9, color='green')\n",
    "\n",
    "plt.plot(months, H_monthyear.transpose(), marker='', linewidth=1.0, alpha=0.9, color='blue')\n",
    "\n",
    "\n",
    "plt.title(\"Seasonal cycle of SH\", loc='left')\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"SH (W/m$^2$)\")\n",
    "\n",
    "\n",
    "plt.text(7, 97, 'Observations', color ='blue', fontsize=15)\n",
    "plt.text(7, 90, 'FATES ensemble members', color ='green', fontsize=15)\n",
    "plt.savefig('sh_seascycle.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the LAI data and plot the data on the same joint distribution plot as the model ensemble\n",
    "lai_datafilename = 'benchmark_datasets/LAI.csv'\n",
    "lai_data = pd.read_csv(lai_datafilename)\n",
    "\n",
    "laimean = np.array([lai_data['LAI '][:].mean()])\n",
    "laistd = np.array([lai_data['LAI '][:].std()])\n",
    "gppmean = np.array([gpp_gcm2y.mean()])\n",
    "gppstd = np.array([gpp_gcm2y.std()])\n",
    "angle = np.array([0.])\n",
    "\n",
    "lai_ens = lai_series.values\n",
    "gpp_ens = gpp_series.values\n",
    "\n",
    "map_funcs.xyplot(lai_ens, gpp_ens, dots=True, xtitle='LAI', ytitle='GPP(gC m~S~-2~N~ y~S~-1~N~)', showjupyter=True, file='lai_v_gpp', overlay_ellipses_x=laimean, overlay_ellipses_y=gppmean, overlay_ellipses_xaxis=laistd, overlay_ellipses_yaxis=gppstd, overlay_ellipses_angle=angle, overlay_ellipses_color='black', overlay_ellipses_filled=True, overlay_ellipses_opacity=0.3)\n",
    "laistd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census Data\n",
    "\n",
    "We want to load the size-structured FATES output data and compare this to BCI census data.\n",
    "\n",
    "#### First load the raw size distribution data.  Plot as number density in log/log space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nplant_scls = histfile2.variables['NPLANT_SCLS']\n",
    "fates_levscls = histfile2.variables['fates_levscls'][:]\n",
    "\n",
    "nlevscls= len(fates_levscls)\n",
    "\n",
    "levscls_ext = np.append(fates_levscls,200.)\n",
    "dlevscls = levscls_ext[1:] - levscls_ext[0:len(levscls_ext)-1]\n",
    "levscls_mid = fates_levscls + dlevscls/2.\n",
    "levscls_ext_logscale = levscls_ext.copy()\n",
    "levscls_ext_logscale[0] = .5\n",
    "\n",
    "nplant_scls_timeave = nplant_scls[:,startyear:endyear,:,0].mean(axis=1)\n",
    "\n",
    "nplant_scls_timeave_n_percm =  nplant_scls_timeave/dlevscls\n",
    "\n",
    "## open BCI inventory data plot                                                                                                                                 \n",
    "filename_bci_inventory = 'benchmark_datasets/census_bmks_lscaled_allyears_1pft_v4_25scbci_181101.nc'\n",
    "fin_bci_inv = nc4.Dataset(filename_bci_inventory)\n",
    "\n",
    "## load size distributions from census data\n",
    "sizedist_inv = fin_bci_inv.variables['abund_by_size_census'][:,:,1]\n",
    "sizedist_inv_timeave = sizedist_inv[:,:].mean(axis=0)\n",
    "\n",
    "# get error on obs and ready that too                                                                                                                           \n",
    "sizedist_inv_error_ll = np.ma.masked_all([2,len(levscls_mid)-1])\n",
    "sizedist_inv_error_ul = np.ma.masked_all([2,len(levscls_mid)-1])\n",
    "sizedist_inv_error_ll[1,:] = fin_bci_inv.variables['abund_by_size_census'][:,:,0].min(axis=0)/dlevscls[1:]\n",
    "sizedist_inv_error_ul[1,:] = fin_bci_inv.variables['abund_by_size_census'][:,:,2].max(axis=0)/dlevscls[1:]\n",
    "\n",
    "fig=plt.figure(figsize=(10, 10))\n",
    "\n",
    "for column in range(nens):\n",
    "    plt.loglog(levscls_mid[1:], nplant_scls_timeave_n_percm[column,1:], marker='', linewidth=0.25, alpha=0.9, color='green')\n",
    "\n",
    "plt.loglog(levscls_mid[1:], sizedist_inv[:].mean(axis=0)/dlevscls[1:], marker='', linewidth=1.5, alpha=0.9, color='blue')\n",
    "\n",
    "# Add titles\n",
    "plt.title(\"Tree Size Distributions\", loc='left')\n",
    "plt.xlabel(\"Tree Diameter (cm)\")\n",
    "plt.ylabel(\"Tree number density (n/ha/cm)\")\n",
    "plt.ylim(ymin=1e-2)\n",
    "\n",
    "\n",
    "plt.text(30, 1e4, 'Observations', color ='blue', fontsize=15)\n",
    "plt.text(30, 0.6e4, 'FATES ensemble members', color ='green', fontsize=15)\n",
    "plt.savefig('sizedist.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot growth rates, conditional on size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read census data\n",
    "growth_rate_inv = fin_bci_inv.variables['growth_increment_by_size_census'][:,:,1]\n",
    "dclass_inv = fin_bci_inv.variables['dclass'][:]\n",
    "ddbh_inv_error_ll = np.ma.masked_all([2,len(levscls_mid)])\n",
    "ddbh_inv_error_ul = np.ma.masked_all([2,len(levscls_mid)])\n",
    "ddbh_inv_error_ll[1,1:] = fin_bci_inv.variables['growth_increment_by_size_census'][1:,:,0].min(axis=0)\n",
    "ddbh_inv_error_ul[1,1:] = fin_bci_inv.variables['growth_increment_by_size_census'][1:,:,2].max(axis=0)\n",
    "\n",
    "## FATES\n",
    "ddbh_scls = (histfile2.variables['DDBH_CANOPY_SCLS'][:,startyear:endyear,:,0].mean(axis=1) \n",
    "             + histfile2.variables['DDBH_UNDERSTORY_SCLS'][:,startyear:endyear,:,0].mean(axis=1)\n",
    "            )/ nplant_scls_timeave\n",
    "\n",
    "fig=plt.figure(figsize=(24, 24))\n",
    "\n",
    "for column in range(nens):\n",
    "    plt.plot(levscls_mid[1:], ddbh_scls[column,1:], marker='', linewidth=0.25, alpha=0.9, color='green')\n",
    "\n",
    "plt.plot(levscls_mid[1:], growth_rate_inv[:].mean(axis=0), marker='', linewidth=1.5, alpha=0.9, color='blue')\n",
    "\n",
    "\n",
    "# Add titles\n",
    "plt.title(\"Tree Growth Rates\", loc='left')\n",
    "plt.xlabel(\"Tree Diameter (cm)\")\n",
    "plt.ylabel(\"Diameter Increment (cm/yr)\")\n",
    "plt.ylim(ymax=10)\n",
    "plt.ylim(ymin=0)\n",
    "\n",
    "plt.text(100, 3.6, 'Observations', color ='blue', fontsize=15)\n",
    "plt.text(100, 3.4, 'FATES ensemble members', color ='green', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FATES DDBH by canopy strata\n",
    "\n",
    "\n",
    "nplant_canopy_scls = histfile2.variables['NPLANT_CANOPY_SCLS']\n",
    "nplant_canopy_scls_timeave = nplant_canopy_scls[:,startyear:endyear,:,0].mean(axis=1)\n",
    "\n",
    "ddbh_canopy_scls = (histfile2.variables['DDBH_CANOPY_SCLS'][:,startyear:endyear,:,0].mean(axis=1) \n",
    "            )/ nplant_canopy_scls_timeave\n",
    "\n",
    "fig=plt.figure(figsize=(24, 24))\n",
    "\n",
    "for column in range(nens):\n",
    "    plt.plot(levscls_mid[1:], ddbh_canopy_scls[column,1:], marker='', linewidth=0.25, alpha=0.9, color='green')\n",
    "\n",
    "# Add titles\n",
    "plt.title(\"Canopy Tree Growth Rates\", loc='left')\n",
    "plt.xlabel(\"Tree Diameter (cm)\")\n",
    "plt.ylabel(\"Diameter Increment (cm/yr)\")\n",
    "plt.ylim(ymax=10)\n",
    "plt.ylim(ymin=0)\n",
    "\n",
    "plt.text(100, 3.6, 'Observations', color ='blue', fontsize=15)\n",
    "plt.text(100, 3.4, 'FATES ensemble members', color ='green', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mortality Rates, as conditional on size distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load census data\n",
    "mort_rate_inv = fin_bci_inv.variables['mortality_rate_by_size_census'][:,:,1]\n",
    "mort_rate_inv_mean = mort_rate_inv[1:,:].mean(axis=0)\n",
    "    \n",
    "mort_inv_error_ll = np.ma.masked_all([2,len(levscls_mid)])\n",
    "mort_inv_error_ul = np.ma.masked_all([2,len(levscls_mid)])\n",
    "mort_inv_error_ll[1,1:] = fin_bci_inv.variables['mortality_rate_by_size_census'][1:,:,0].min(axis=0)\n",
    "mort_inv_error_ul[1,1:] = fin_bci_inv.variables['mortality_rate_by_size_census'][1:,:,2].max(axis=0)\n",
    "\n",
    "## FATES\n",
    "mortality_scls = (histfile2.variables['MORTALITY_CANOPY_SCLS'][:,startyear:endyear,:,0].mean(axis=1) + \n",
    "                 histfile2.variables['MORTALITY_UNDERSTORY_SCLS'][:,startyear:endyear,:,0].mean(axis=1)\n",
    "                 ) / nplant_scls_timeave\n",
    "\n",
    "fig=plt.figure(figsize=(24, 24))\n",
    "\n",
    "for column in range(nens):\n",
    "    plt.plot(levscls_mid[1:], mortality_scls[column,1:], marker='', linewidth=0.15, alpha=0.9, color='green')\n",
    "\n",
    "plt.plot(levscls_mid[1:], mort_rate_inv_mean, marker='', linewidth=1.5, alpha=0.9, color='blue')\n",
    "\n",
    "\n",
    "# Add titles\n",
    "plt.title(\"Tree Mortality Rates\", loc='left')\n",
    "plt.xlabel(\"Tree Diameter (cm)\")\n",
    "plt.ylabel(\"Mortality Rate (1/yr)\")\n",
    "plt.ylim(ymax=0.4)\n",
    "\n",
    "\n",
    "plt.text(100, 0.33, 'Observations', color ='blue', fontsize=15)\n",
    "plt.text(100, 0.32, 'FATES ensemble members', color ='green', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we want to plot recruitment rates into each size class for the model and for observations\n",
    " Calculate recruitment into each bin.  This is now an output variable of FATES.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load recruitment rates\n",
    "## use new growthflux variables\n",
    "\n",
    "use_new_counting_method = True\n",
    "\n",
    "if use_new_counting_method:\n",
    "    ### new way of doing it\n",
    "    growthflux_fusion_scpf = histfile2.variables['GROWTHFLUX_FUSION_SCPF'][:,startyear:endyear,0:26,0].mean(axis=1)\n",
    "    growthflux_scpf = histfile2.variables['GROWTHFLUX_SCPF'][:,startyear:endyear,0:26,0].mean(axis=1)\n",
    "    recruitment_rate_into_bin_i = np.ma.masked_array(growthflux_fusion_scpf +growthflux_scpf)\n",
    "else:\n",
    "    ## this is the old way of calculating recruitment, based on continuity\n",
    "    recruitment_rate_smallest = histfile2.variables['RECRUITMENT'][:,startyear:endyear,:,0].sum(axis=2).mean(axis=1)\n",
    "    print((endyear - startyear))\n",
    "    recruitment_rate_into_bin_i = np.zeros([nens,nlevscls])\n",
    "    recruitment_rate_into_bin_i[:,0] = recruitment_rate_smallest[:]\n",
    "    mort_rate = (histfile2.variables['MORTALITY_CANOPY_SCLS'][:,startyear:endyear,:,0].mean(axis=1) + \n",
    "                histfile2.variables['MORTALITY_UNDERSTORY_SCLS'][:,startyear:endyear,:,0].mean(axis=1)\n",
    "                )\n",
    "    for i in range(nlevscls-1):\n",
    "        recruitment_rate_into_bin_i[:,i+1] = (nplant_scls[:,endyear,i,0] - nplant_scls[:,startyear,i,0])/(endyear - startyear) + recruitment_rate_into_bin_i[:,i] - mort_rate[:,i]\n",
    "\n",
    "## load census data\n",
    "recruit_rate_inv = fin_bci_inv.variables['new_recruits_by_size_census'][:,:,1]\n",
    "recruit_rate_inv_mean = recruit_rate_inv[1:,:].mean(axis=0)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "fig=plt.figure(figsize=(24, 24))\n",
    "\n",
    "## the lower bound for trees is treated as zero, but really there aren't any zero-cm dbh trees.  setting this as an arbitrary number for now.\n",
    "fates_levscls[0] = 0.1\n",
    "\n",
    "for column in range(nens):\n",
    "    plt.loglog(fates_levscls[:], recruitment_rate_into_bin_i[column,:], marker='', linewidth=0.15, alpha=0.9, color='green')\n",
    "        \n",
    "plt.loglog(fates_levscls[1:], recruit_rate_inv_mean, marker='', linewidth=1.5, alpha=0.9, color='blue')\n",
    "\n",
    "#\n",
    "## Add titles\n",
    "plt.ylim(ymin=1e-2)\n",
    "plt.title(\"Tree Recruitment Rates\", loc='left')\n",
    "plt.xlabel(\"Tree Diameter (cm)\")\n",
    "plt.ylabel(\"Recruitment Rate into size class (n/ha/yr)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "#plt.ylim(ymin=1e-2)\n",
    "#f_recruit = pd.DataFrame(np.concatenate((np.expand_dims(fates_levscls[:],1),recruitment_rate_into_bin_i.transpose()),axis=1))\n",
    "#print(np.expand_dims(fates_levscls[:],1).shape)\n",
    "#print(recruitment_rate_into_bin_i.transpose().shape)\n",
    "#f_recruit.columns = ['Size'] + ['ens'] * 767\n",
    "#g = sns.relplot(x=\"size\", y=\"ens\", kind=\"line\", data=f_recruit)\n",
    "#map_funcs.xyplot()\n",
    "#f_recruit\n",
    "#recruitment_rate_into_bin_i[recruitment_rate_into_bin_i[:] <= 0.].mask=True\n",
    "recruitment_rate_into_bin_i = np.ma.masked_where(recruitment_rate_into_bin_i[:] <= 0., recruitment_rate_into_bin_i)\n",
    "#print(recruitment_rate_into_bin_i.min())\n",
    "#print(fates_levscls[:])\n",
    "fates_levscls[0] = 0.1\n",
    "xdata = np.repeat(np.expand_dims(fates_levscls[:],1), nens,axis=1).transpose()\n",
    "#print(xdata.shape)\n",
    "map_funcs.xyplot(xdata, recruitment_rate_into_bin_i, file='recrate',ylog=True,xlog=True,yrange=[1e-2,1e5],xrange=[fates_levscls[0],200],linethickness=0.01,shaded_line_data=crown_area_index, shaded_line_levels=np.arange(0.,2.1,0.2),colormap='rainbow',xtitle='Diameter (cm)',ytitle='Recruitment Rate (N/ha/yr)')\n",
    "map_funcs.pdf_to_png('recrate')\n",
    "Image(\"recrate.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show histograms of small-tree mortality as conditional on the number of canopy layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seedling_mortality_array = np.ma.masked_invalid(np.log10(recruitment_rate_into_bin_i[:,1]/recruitment_rate_into_bin_i[:,0]))\n",
    "seedling_mortality = pd.DataFrame(seedling_mortality_array)\n",
    "#print(seedling_mortality.shape)\n",
    "seedling_mortality.columns = [\"seedling_mort\"]\n",
    "seedling_mortality[\"crownarea\"] = pd.cut(crown_area_index, bins=np.arange(11)*.2)\n",
    "#sns.distplot(seedling_mortality[\"seedling_mort\"])\n",
    "#print(seedling_mortality)\n",
    "\n",
    "\n",
    "#ax = sns.scatterplot(x=\"crownarea\", y=\"seedling_mort\", data=seedling_mortality)\n",
    "ax = sns.scatterplot(x=crown_area_index, y=seedling_mortality_array)\n",
    "plt.title(\"Seedling survival as function of canopy thickness\", loc='left')\n",
    "plt.xlabel(\"Crown Area Index\")\n",
    "plt.ylabel(\"log(Survival rate of <1cm trees)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = sns.scatterplot(x=\"crownarea\", y=\"seedling_mort\", data=seedling_mortality)\n",
    "ax = sns.scatterplot(x=mean_lai, y=seedling_mortality_array)\n",
    "plt.title(\"Seedling survival as function of LAI\", loc='left')\n",
    "plt.xlabel(\"Leaf Area Index\")\n",
    "plt.ylabel(\"log(Survival rate of <1cm trees)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ay = sns.scatterplot(x=np.log10(df_traits[\"C Starv Mort.\"]), y=seedling_mortality_array)\n",
    "plt.title(\"Seedling Survival as f(C starve mort)\", loc='left')\n",
    "plt.xlabel(\"cstarv_mort\")\n",
    "plt.ylabel(\"log(Survival rate of <1cm trees)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_traits_log[\"seedling_mort\"] = pd.cut(-seedling_mortality_array, bins=np.arange(10)*0.25)\n",
    "biomassscatterplot = sns.pairplot(df_traits_log, hue=\"seedling_mort\",\n",
    "                 hue_order=df_traits_log.seedling_mort.cat.categories,\n",
    "                 palette=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_med = 70.\n",
    "size_large = 120.\n",
    "\n",
    "lev_med = np.argmin(np.abs(levscls_mid - size_med))\n",
    "#print(lev_med)\n",
    "lev_large = np.argmin(np.abs(levscls_mid - size_large))\n",
    "#print(lev_large)\n",
    "\n",
    "ratio_med_large = np.ma.masked_invalid(nplant_scls_timeave_n_percm[:,lev_large] / nplant_scls_timeave_n_percm[:,lev_med])\n",
    "#print(ratio_med_large)\n",
    "\n",
    "df_traits_log[\"ratio_med_large\"] = pd.cut(ratio_med_large, bins=np.array([0.01,0.02,0.05,0.1,0.2,0.5,1.,2.,5.]))\n",
    "biomassscatterplot = sns.pairplot(df_traits_log, hue=\"ratio_med_large\",\n",
    "                 hue_order=df_traits_log.ratio_med_large.cat.categories,\n",
    "                 palette=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### explore some trait control on basic ecosystem rates\n",
    "refsize = 20.\n",
    "lev_refsize = np.argmin(np.abs(levscls_mid - refsize))\n",
    "\n",
    "nplant_scls_canopy = histfile2.variables['NPLANT_CANOPY_SCLS']\n",
    "nplant_scls_canopy_timeave = nplant_scls_canopy[:,startyear:endyear,:,0].mean(axis=1)\n",
    "\n",
    "mortrate_canopy = np.ma.masked_invalid(histfile2.variables['MORTALITY_CANOPY_SCLS'][:,startyear:endyear,lev_refsize,0].mean(axis=1) / nplant_scls_canopy_timeave[:,lev_refsize])\n",
    "mortrate_canopy.mean()\n",
    "df_traits_log[\"mortrate_canopy\"] = pd.cut(mortrate_canopy, bins=np.arange(10)*0.005)\n",
    "mortrate_canopy_scatterplot = sns.pairplot(df_traits_log, hue=\"mortrate_canopy\",\n",
    "                 hue_order=df_traits_log.mortrate_canopy.cat.categories,\n",
    "                 palette=\"YlGnBu\")\n",
    "\n",
    "mortrate_canopy_scatterplot.savefig('mortrate_canopy_pairplot.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### explore some trait control on basic ecosystem rates\n",
    "\n",
    "nplant_scls_understory = histfile2.variables['NPLANT_UNDERSTORY_SCLS']\n",
    "nplant_scls_understory_timeave = nplant_scls_understory[:,startyear:endyear,:,0].mean(axis=1)\n",
    "\n",
    "mortrate_understory = np.ma.masked_invalid(histfile2.variables['MORTALITY_UNDERSTORY_SCLS'][:,startyear:endyear,lev_refsize,0].mean(axis=1) / nplant_scls_understory_timeave[:,lev_refsize])\n",
    "\n",
    "mortrate_understory.mean()\n",
    "df_traits_log[\"mortrate_understory\"] = pd.cut(mortrate_understory, bins=np.array([0.,0.01,0.02,0.05,0.1,0.2,0.5,1.]))\n",
    "mortrate_understory_scatterplot = sns.pairplot(df_traits_log, hue=\"mortrate_understory\",\n",
    "                 hue_order=df_traits_log.mortrate_understory.cat.categories,\n",
    "                 palette=\"YlGnBu\")\n",
    "\n",
    "mortrate_understory_scatterplot.savefig('mortrate_understory_pairplot.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### explore some trait control on basic ecosystem rates\n",
    "\n",
    "growthrate_canopy = np.ma.masked_invalid(histfile2.variables['DDBH_CANOPY_SCLS'][:,startyear:endyear,lev_refsize,0].mean(axis=1) / nplant_scls_canopy_timeave[:,lev_refsize])\n",
    "\n",
    "growthrate_canopy.mean()\n",
    "print(growthrate_canopy.shape)\n",
    "df_traits_log[\"growthrate_canopy\"] = pd.cut(growthrate_canopy, bins=np.arange(10)*0.5)\n",
    "growthratescatterplot = sns.pairplot(df_traits_log, hue=\"growthrate_canopy\",\n",
    "                 hue_order=df_traits_log.growthrate_canopy.cat.categories,\n",
    "                 palette=\"YlGnBu\")\n",
    "\n",
    "growthratescatterplot.savefig('growthrate_canopy_pairplot.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### explore some trait control on basic ecosystem rates\n",
    "\n",
    "growthrate_understory = np.ma.masked_invalid(histfile2.variables['DDBH_UNDERSTORY_SCLS'][:,startyear:endyear,lev_refsize,0].mean(axis=1) / nplant_scls_understory_timeave[:,lev_refsize])\n",
    "\n",
    "growthrate_understory.mean()\n",
    "print(growthrate_understory.shape)\n",
    "df_traits_log[\"growthrate_understory\"] = pd.cut(growthrate_understory, bins=np.array([0.,0.01,.02,.05,.1,.2,.5,1.,2.]))\n",
    "growthrate_understory_scatterplot = sns.pairplot(df_traits_log, hue=\"growthrate_understory\",\n",
    "                 hue_order=df_traits_log.growthrate_understory.cat.categories,\n",
    "                 palette=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertical profiles profiles of canopy and leaf height (to compare to LIDAR data)\n",
    "#### First plot the vertical profile of leaf area, which does not take into account any information about the relative position of leaves with respect to each other, just where all the leaves are through the canopy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heightlevs = histfile2.variables['fates_levheight'][:]\n",
    "dz = heightlevs[1]-heightlevs[0]\n",
    "heightlevs_midpoint = dz/2. + heightlevs\n",
    "\n",
    "### load LIDAR estimate of LAD from Detto et al 2015\n",
    "filename_lidar_leafareadens = 'benchmark_datasets/LAD.csv'\n",
    "lidar_leafareadens_file = pd.read_csv(filename_lidar_leafareadens)\n",
    "#print(lidar_leafareadens_file.dtypes)\n",
    "#print(lidar_leafareadens_file['Height (m)'].values)\n",
    "#print(lidar_leafareadens_file['LAD'].values)\n",
    "\n",
    "\n",
    "leafheight = histfile2.variables['LEAF_HEIGHT_DIST'][:,startyear:endyear,:,0].mean(axis=1) / dz\n",
    "\n",
    "fig=plt.figure(figsize=(24, 24))\n",
    "\n",
    "for column in range(nens):\n",
    "    plt.plot(leafheight[column,:], heightlevs_midpoint[:], marker='', linewidth=0.15, alpha=0.9, color='green')\n",
    "\n",
    "plt.plot(lidar_leafareadens_file['LAD'], 1.*lidar_leafareadens_file['Height (m)'], marker='', linewidth=1.5, alpha=0.9, color='blue')\n",
    "\n",
    "plt.title(\"Leaf height distributions\", loc='left')\n",
    "plt.xlabel(\"LAI vertical density (m2/m3)\")\n",
    "plt.ylabel(\"height(m)\")\n",
    "plt.ylim(0.,50.)\n",
    "plt.text(0.8, 47, 'Observations', color ='blue', fontsize=15)\n",
    "plt.text(0.8, 45, 'FATES ensemble members', color ='green', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next plot the vertical profile of top canopy height, which is the top of each cohort that is in the canopy strata, so is the other extreme endmember of a height distributio that takes relative position completely into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canopyheight = histfile2.variables['CANOPY_HEIGHT_DIST'][:,startyear:endyear,:,0].mean(axis=1)/ dz\n",
    "\n",
    "fig=plt.figure(figsize=(12, 12))\n",
    "\n",
    "for column in range(nens):\n",
    "    plt.plot(canopyheight[column,:], heightlevs_midpoint[:], marker='', linewidth=0.15, alpha=0.9, color='green')\n",
    "\n",
    "\n",
    "plt.title(\"Canopy height distributions\", loc='left')\n",
    "plt.xlabel(\"Canopy top vertical density (m2/m3)\")\n",
    "plt.ylabel(\"height(m)\")\n",
    "plt.ylim(0.,50.)\n",
    "#plt.text(0.3, 47, 'Observations', color ='blue', fontsize=15)\n",
    "plt.text(0.3, 45, 'FATES ensemble members', color ='green', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first calculate the potential variance decomposition\n",
    "vars_toassess = [mean_gpp,mean_lai,final_biomass,growthrate_canopy,growthrate_understory,mortrate_canopy,mortrate_understory]\n",
    "\n",
    "nvars_to_assess = len(vars_toassess)\n",
    "potential_variance_decomposition_data = np.zeros([nvars_to_assess,ncols])\n",
    "\n",
    "for var_i in range(nvars_to_assess):\n",
    "    for par_i in range(ncols):\n",
    "        #\n",
    "        good_data = np.ma.masked_invalid(vars_toassess[var_i])\n",
    "        dataindices_touse = np.logical_not(np.ma.getmaskarray(good_data))\n",
    "        y_unordered = good_data[dataindices_touse]\n",
    "        x_unordered = traits_matrix[dataindices_touse,par_i]\n",
    "        order = x_unordered.argsort()\n",
    "        x = x_unordered[order]\n",
    "        y = y_unordered[order]\n",
    "        #\n",
    "        thespline = interpolate.UnivariateSpline(x, y, s=1e10, k=3)\n",
    "        spline_prediction = thespline(x)\n",
    "        #\n",
    "        map_funcs.xyplot(x,y,overlay_x=x,overlay_y=spline_prediction,showjupyter=True,dots=True, dotsize=0.01)\n",
    "        #\n",
    "        potential_variance_decomposition_data[var_i,par_i] = spline_prediction.var() / y.var()\n",
    "        #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next calculate the minimum variance decomposition\n",
    "\n",
    "minimum_variance_decomposition_data = np.zeros([nvars_to_assess,ncols])\n",
    "\n",
    "for var_i in range(nvars_to_assess):\n",
    "    for par_i in range(ncols):\n",
    "        #\n",
    "        good_data = np.ma.masked_invalid(vars_toassess[var_i])\n",
    "        dataindices_touse = np.logical_not(np.ma.getmaskarray(good_data))\n",
    "        y_unordered = good_data[dataindices_touse]\n",
    "        y_unordered_residual = y_unordered.copy()\n",
    "        #\n",
    "        # to calculate the minimum variance, first subtract the fraction explained by all other variables\n",
    "        print()\n",
    "        for par_j in range(ncols):\n",
    "            if par_i != par_j:\n",
    "                #\n",
    "                x_unordered_othervar = traits_matrix[dataindices_touse,par_j]\n",
    "                order_othervar = x_unordered_othervar.argsort()\n",
    "                order_othervar_togetback = order_othervar.argsort()\n",
    "                #\n",
    "                x_othervar = x_unordered_othervar[order_othervar]\n",
    "                y_othervar = y_unordered_residual[order_othervar]                \n",
    "                #\n",
    "                thespline_othervar = interpolate.UnivariateSpline(x_othervar, y_othervar, s=1e10, k=3)\n",
    "                spline_prediction_othervar = thespline_othervar(x_othervar)\n",
    "                #map_funcs.xyplot(x_othervar,y_othervar,overlay_x=x_othervar,overlay_y=spline_prediction_othervar,showjupyter=True,dots=True, dotsize=0.01)\n",
    "                #\n",
    "                y_unordered_residual = y_unordered_residual - spline_prediction_othervar[order_othervar_togetback]\n",
    "                print(spline_prediction_othervar.mean(), y_unordered.var(), y_unordered_residual.var())\n",
    "        #\n",
    "        x_unordered = traits_matrix[dataindices_touse,par_i]\n",
    "        order = x_unordered.argsort()\n",
    "        #\n",
    "        x = x_unordered[order]\n",
    "        #\n",
    "        y_residual = y_unordered_residual[order]\n",
    "        y = y_unordered[order]\n",
    "        #\n",
    "        thespline_residual = interpolate.UnivariateSpline(x, y_residual, s=1e10, k=3)\n",
    "        spline_prediction_residual = thespline_residual(x)\n",
    "        #\n",
    "        map_funcs.xyplot(x,y_residual,overlay_x=x,overlay_y=spline_prediction_residual,showjupyter=True,dots=True, dotsize=0.01)\n",
    "        #\n",
    "        minimum_variance_decomposition_data[var_i,par_i] = spline_prediction_residual.var() / y.var()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now plot this data as a stemplot\n",
    "reload(map_funcs)\n",
    "varnames = ['GPP','LAI','Biomass','Can. Growth Rate','Und. Growth Rate','Can. Mort. Rate','Und. Mort. Rate']\n",
    "\n",
    "map_funcs.stemplot(potential_variance_decomposition_data, parameter_labels=column_names, variable_labels=varnames, showjupyter=True, file='variance_decomp', parameter_labelsize=.01, variable_labelsize=.01, plot_xmargins=.02, margins_space=.02, maxticks=3, dotsize=0.01, png_dens=300.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_funcs.stemplot(potential_variance_decomposition_data, overlay_data = minimum_variance_decomposition_data, parameter_labels=column_names, variable_labels=varnames, showjupyter=True, file='variance_decomp_potential_minimum', parameter_labelsize=.01, variable_labelsize=.01, plot_xmargins=.02, margins_space=.02, maxticks=3, dotsize=0.01, png_dens=300.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####not using this right now: R approach to spline fitting\n",
    "\n",
    "stats = importr('stats')\n",
    "base = importr('base')\n",
    "splines = importr('splines')\n",
    "SemiPar = importr('SemiPar')\n",
    "\n",
    "par_indx = 0\n",
    "var_indx = 0\n",
    "vars_toassess = [mean_gpp,mean_lai,final_biomass,growthrate_canopy,mortrate_canopy,mortrate_understory]\n",
    "#\n",
    "good_data = np.ma.masked_invalid(vars_toassess[var_indx])\n",
    "dataindices_touse = np.logical_not(np.ma.getmaskarray(good_data))\n",
    "#\n",
    "xdata_rvect = robjects.FloatVector(traits_matrix[dataindices_touse,par_indx])\n",
    "ydata_rvect = robjects.FloatVector(good_data[dataindices_touse])\n",
    "#\n",
    "robjects.globalenv[\"xdata_rvect\"] = xdata_rvect\n",
    "robjects.globalenv[\"ydata_rvect\"] = ydata_rvect\n",
    "#\n",
    "spline = SemiPar.spm(\"ydata_rvect~f(xdata_rvect)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traits_matrix[dataindices_touse,par_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allocation\n",
    "#### Plot some ternary diagrams of ecosystem allocation between leaves, wood, and fine roots.  Color the diagrams by some of the more interesting parametric predictors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "imp.reload(plt)\n",
    "import ternary\n",
    "\n",
    "nppleaf = histfile.variables['NPP_LEAF'][:,startyear*12:endyear*12,0].mean(axis=1)\n",
    "nppfroot = histfile.variables['NPP_FROOT'][:,startyear*12:endyear*12,0].mean(axis=1)\n",
    "nppwood = histfile.variables['NPP_CROOT'][:,startyear*12:endyear*12,0].mean(axis=1) + histfile.variables['NPP_STEM'][:,startyear*12:endyear*12,0].mean(axis=1)\n",
    "\n",
    "nppsum = nppleaf + nppfroot + nppwood\n",
    "\n",
    "mask = nppsum < nppsum.max()*1e-3\n",
    "nppleaf = np.ma.masked_array(nppleaf, mask=mask)\n",
    "nppfroot = np.ma.masked_array(nppfroot, mask=mask)\n",
    "nppwood = np.ma.masked_array(nppwood, mask=mask)\n",
    "\n",
    "allocdata = 100. * (np.column_stack([nppleaf, nppwood, nppfroot]).transpose() / (nppsum)).transpose()\n",
    "\n",
    "# Scatter Plot\n",
    "size = 6\n",
    "scale = 100\n",
    "fontsize=20\n",
    "\n",
    "interesting_alocation_predictors = [0,4,6,8,9]\n",
    "\n",
    "for i in range(len(interesting_alocation_predictors)):\n",
    "    column = interesting_alocation_predictors[i]\n",
    "    colors = traits_matrix[:,column]\n",
    "\n",
    "    figure, tax = ternary.figure(scale=scale)\n",
    "    figure.set_size_inches(1.3*size, size)\n",
    "    tax.set_title(\"Allocation diagram, as colored by \"+column_names[column], fontsize=fontsize)\n",
    "    tax.boundary(linewidth=2.0)\n",
    "    tax.gridlines(multiple=5, color=\"blue\")\n",
    "    # Plot a few different styles with a legend\n",
    "    #tax.scatter(allocdata, marker='s', color='red')\n",
    "    tax.scatter(allocdata, vmax=max(colors),vmin=min(colors),colormap=plt.cm.viridis,colorbar=True,c=colors,cmap=plt.cm.viridis)\n",
    "    tax.ticks(axis='lbr', linewidth=1, multiple=10)\n",
    "    tax.left_axis_label(\"fine root NPP\", fontsize=fontsize)\n",
    "    tax.right_axis_label(\"wood NPP\", fontsize=fontsize)\n",
    "    tax.bottom_axis_label(\"leaves NPP\", fontsize=fontsize)\n",
    "    tax.legend()\n",
    "    ##print(df_traits.shape)\n",
    "    tax.clear_matplotlib_ticks()\n",
    "    tax.show()\n",
    "##print(allocdata[:,2].max(), allocdata[:,2].min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Litterfall.  Compare observations of leaf litterfall to model predictions of leaf allocation (which will be the same as litterfall at steady state).  We can compare seasonality once we add a litterfall flux term to the FATES history output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ingest and plot the Wright et al litterfall data\n",
    "\n",
    "fname_in = 'benchmark_datasets/LeafMassbySpCensus_20170224.txt'\n",
    "\n",
    "df = pd.read_csv(fname_in, sep='\\t', lineterminator='\\r')\n",
    "\n",
    "nrows = len(df) -1\n",
    "\n",
    "nspecies = df['sp'].nunique()\n",
    "ndates = df['YYYY-MM-DD'].nunique()\n",
    "\n",
    "#print(nspecies)\n",
    "#print(ndates)\n",
    "\n",
    "litterfall = np.zeros(ndates)\n",
    "trap_area = np.zeros(ndates)\n",
    "dates = []\n",
    "since_start = np.zeros(ndates)\n",
    "since_prior = np.ma.masked_all(ndates)\n",
    "\n",
    "startday = pd.to_datetime('2008-01-01')\n",
    "\n",
    "for i in range(nrows):\n",
    "    if df['YYYY-MM-DD'][i] not in dates:\n",
    "        dates.append(df['YYYY-MM-DD'][i])\n",
    "    j = dates.index(df['YYYY-MM-DD'][i])\n",
    "    litterfall[j] = litterfall[j] + df['grams'][i]\n",
    "    trap_area[j] = trap_area[j] + 0.25\n",
    "    since_start[j] = (pd.to_datetime(df['YYYY-MM-DD'][i]) - startday).days/ 365.25\n",
    "    #\n",
    "    if j > 0:\n",
    "        since_prior[j] = (pd.to_datetime(df['YYYY-MM-DD'][i]) - pd.to_datetime(dates[j-1])).days/ 365.25\n",
    "\n",
    "litterfall_rate = litterfall / (trap_area * since_prior)  ### in grams per m2 per year\n",
    "\n",
    "fig=plt.figure(figsize=(12, 6))\n",
    "### plot data as continuous timeseries\n",
    "#plt.plot(since_start, litterfall_rate, marker='', linewidth=0.5, alpha=0.9, color='blue')\n",
    "#plt.title(\"Litterfall Rate\", loc='left', fontsize=12, fontweight=0)\n",
    "#plt.xlabel(\"Time (years since Jan 1 2008)\")\n",
    "#plt.ylabel(\"Litterfall (g / m2 / yr)\")\n",
    "\n",
    "### plot data as annual cycles superimposed on each other\n",
    "nyears_litterfall = int(since_start.max() - since_start.min())\n",
    "for i in range(nyears_litterfall):\n",
    "    ind_start = np.argmax(since_start>i)\n",
    "    ind_end = np.argmax(since_start>(i+1))\n",
    "    plt.plot(since_start[ind_start:ind_end]-i, litterfall_rate[ind_start:ind_end], marker='', linewidth=0.5, alpha=0.9, color='blue')\n",
    "plt.title(\"Litterfall Rate\", loc='left', fontsize=12, fontweight=0)\n",
    "plt.xlabel(\"Time (fraction of year)\")\n",
    "plt.ylabel(\"Litterfall (g / m2 / yr)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot litterfall as a histogram of FATES ensemble member mean flux rates, as compared to the mean of the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_leaf_drymatter_to_leafc = .4482  ## mean of leaf samples in norby dataset\n",
    "\n",
    "mean_litterfall_cflux = litterfall_rate.mean() * mean_leaf_drymatter_to_leafc * 1e-3\n",
    "\n",
    "#nppleaf_series = pd.Series(nppleaf, name='NPP leaf')\n",
    "#sns.distplot(nppleaf, kde=False, rug=False, color=\"k\")\n",
    "\n",
    "n, bins, patches =plt.hist((nppleaf.flatten(), np.repeat(mean_litterfall_cflux.mean(),40)), histtype=\"step\",bins=30, color=['green','blue'])\n",
    "plt.xlabel('Leaf C flux (kg C / m2 / yr)')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Leaf C Allocation')\n",
    "\n",
    "plt.text(0.45, 40, 'Observations', color ='blue', fontsize=15)\n",
    "plt.text(0.45, 35, 'FATES ensemble members', color ='green', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
